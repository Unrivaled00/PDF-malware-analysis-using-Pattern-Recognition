{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QO3A7o4_DJob"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PDF MALWARE ANALYSIS SYSTEM USING IMAGE PROCESSING"
      ],
      "metadata": {
        "id": "hmepTFlG4wXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libs"
      ],
      "metadata": {
        "id": "GN9crajHdurt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z1AK28EAdb7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c9e379-7d2c-4299-ed86-c516eb65c4a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "id": "IKDsc82QoNzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97807d8-e74a-4cbd-bbe8-a536c9770adb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import scipy.ndimage as snd\n",
        "import math\n",
        "import progressbar as pb\n",
        "from math import isinf\n",
        "import os\n",
        "import gc\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import scipy.misc as smp \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 #SIFT ALGORITHIM \n",
        "from scipy import ndimage as nd\n",
        "from skimage import exposure\n",
        "from skimage.util import img_as_float \n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor_kernel\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk \n",
        "\n",
        "####################\n",
        "\n",
        "import random\n",
        "# ML Classifiers used chosen + rewritten by us\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import cross_validate\n",
        "import sklearn.metrics as skm\n",
        "import imageio\n",
        "import PIL\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "  "
      ],
      "metadata": {
        "id": "-2llnRA7dsL3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directories"
      ],
      "metadata": {
        "id": "QO3A7o4_DJob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename PDF files to extract label from file name\n",
        "\n",
        "(we renamed the data as a part of our preprocessing to be able to feed it the model by giving each PDF a label before its name) ***|fully by us|***\n",
        "\n"
      ],
      "metadata": {
        "id": "1lhUn5Rj4Lqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_{filee}\"\n",
        "# \tos.rename(src, dst)\n",
        "# \t#shutil.copy(os.path.join(path_of_files_folders, filee), destination)\n",
        "# #os.rename('/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_0_ea-2a_1108.pdf','/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files/0_ea-2a_1108.pdf')"
      ],
      "metadata": {
        "id": "jQGMNtaCH7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files/INFEC_{filee}\"\n",
        "# \tos.rename(src, dst)"
      ],
      "metadata": {
        "id": "566hWMe7bLv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "*   Train: 10,500 file (5,250 benign & 5,250 malicious)\n",
        "*   Test: 4,500 file (2,250 benign & 2,250 malicious)\n",
        "\n",
        "*  Total dataset: 15,000 with a 70:30 split\n",
        "\n",
        "splitting the data into training\\testing sets |fully done by our team| "
      ],
      "metadata": {
        "id": "3JBR-rbFzyX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train 70%"
      ],
      "metadata": {
        "id": "BHjmwZ_A0IaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Benign\n",
        "\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/Project/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#   if c==5250:\n",
        "#     break\n",
        "\n",
        "# print(c)"
      ],
      "metadata": {
        "id": "_wO6gW2l0DDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Malicious\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/Project/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#     if c==5250:\n",
        "#       break"
      ],
      "metadata": {
        "id": "hlWNWTvB0Fxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 30%"
      ],
      "metadata": {
        "id": "JHGVCzCt0Jv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#       TestPath=\"/content/drive/MyDrive/Project/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/Project/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(TestPath,filee))==False and os.path.exists(os.path.join(TrainPath,filee))==False:\n",
        "#         shutil.copy(src, TestPath)\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "2Rj0gc9u0SkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/Project/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#       dst=\"/content/drive/MyDrive/Project/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/Project/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(dst,filee))==False and os.path.exists(os.path.join(TrainPath,filee))==False:\n",
        "#         shutil.copy(src, dst)\n",
        "#         #x=x+1\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "MxOhK-GP0XgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI funcs"
      ],
      "metadata": {
        "id": "LDHObkLWeVWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#|UI functions weren't written by us but some adjustments were made by us* \n",
        "def clear():\n",
        "    \"\"\"Clear screen, return cursor to top left\"\"\"\n",
        "    sys.stdout.write('\\033[2J')\n",
        "    sys.stdout.write('\\033[H')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def prompt(msg=\"Select an option:\", options=[]):\n",
        "    \"\"\"Ask user to select an option or response\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + msg)\n",
        "        count = 0\n",
        "        for option in options:\n",
        "            print(\"\\t{}) {}\".format(count, option))\n",
        "            count += 1\n",
        "        res = input(\" > \")\n",
        "\n",
        "        try:\n",
        "            if  len(options) == 0 or int(res) < len(options):\n",
        "                return res\n",
        "            else:\n",
        "                print(\"Please select a number between 0 and {}\".format(len(options)-1))\n",
        "        except:\n",
        "            print(\"Please provide a valid response\")\n"
      ],
      "metadata": {
        "id": "W1E7zReQeYeE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing funcs"
      ],
      "metadata": {
        "id": "_BuvVnj5dyw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#before running sift algorithim we had to transform PDF files into images these preprocessing functions are concerned with creating the byte plots that i told you about today*\n",
        "\n",
        "#get dims function isn't written by me it was was written by someone else in our group, this was one of the issues we faced during our first trials we found this snippet on stackoverflow, the function is checking each byteplpot size (depending on number of pages for a pdf)\n",
        "# and its giving width for each img + size\n",
        "def getDims(f):\n",
        "    size = len(f) * .001\n",
        "    if (size <= 10):\n",
        "        width = 32\n",
        "    elif (size <= 30):\n",
        "        width = 64\n",
        "    elif (size <= 60):\n",
        "        width = 128\n",
        "    elif (size <= 100):\n",
        "        width = 256\n",
        "    elif (size <= 200):\n",
        "        width = 384\n",
        "    elif (size <= 500):\n",
        "        width = 512\n",
        "    elif (size <= 1000):\n",
        "        width = 768\n",
        "    else:\n",
        "        width = 1024\n",
        "    return (width, math.ceil(size*1000 // width)+ 1)\n",
        "#This function will then create the byte plot arrays in response to each PDF being given a (size, width) \n",
        "def bytePlot(f):\n",
        "    dimensions = getDims(f)\n",
        "    data = np.array(f)\n",
        "    data = np.pad(\n",
        "        data, (0, dimensions[0]-(len(data)%dimensions[0])), 'constant')\n",
        "    data = np.reshape(data, (-1, dimensions[0]))\n",
        "    return data\n",
        "\n",
        "\n",
        "#|not ours| this function builds the image and its target (PDF file)\n",
        "def buildImages(files, targets):\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        with open(file, \"rb\") as f:\n",
        "            \n",
        "            images.append(bytePlot(list(f.read())))\n",
        "            \n",
        "            imageio.imwrite(\"{}.png\".format(file), images[-1])\n",
        "\n",
        "    return images, targets\n",
        "#|not ours| image is then created \n",
        "def loadImages(files, targets):\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        images.append(cv2.imread(file))\n",
        "    return images, targets\n",
        "#|not ours| this function is going to return file names and its page names(plots)\n",
        "def imagePages(files, choice):\n",
        "    targets = []\n",
        "    pageNames = []\n",
        "    pageSize = 100\n",
        "    pages = range(math.ceil(len(files)/pageSize))\n",
        "    for page in pb.progressbar(pages):\n",
        "        gc.collect()\n",
        "\n",
        "        images = []\n",
        "        start = page*pageSize\n",
        "        if choice == \"Create\":\n",
        "            images, targets = buildImages(files[start:start+pageSize], targets)#, type)\n",
        "        elif choice == \"Load\":\n",
        "            images, targets = loadImages(files[start:start+pageSize], targets)\n",
        "        \n",
        "        pageNames.append(\"images_page{}.npy\".format(page))\n",
        "        np.save(pageNames[-1], images)\n",
        "    return targets, pageNames\n",
        "#this function is a part of our UI functions, an option is given to the user--> load or create, if we choose load the function will iterate over piles ending .png (that was created earlier) else it will iterate over files ending with .pdf both types are in one directory\n",
        "# this function will return three outputs (files names, pagenames---> both are known using imagepages function), targets\n",
        "def process(directory): \n",
        "    \"\"\"Process each file in a directory, saving or loading images as directed\"\"\"\n",
        "    files = []\n",
        "\n",
        "    options = [\"Load\", \"Create\"]\n",
        "    choice = options[int(prompt(options=options))]\n",
        "\n",
        "    for item in os.listdir(directory):\n",
        "        if os.path.isfile(os.path.join(directory, item)):\n",
        "            filename = os.path.join(directory, item)\n",
        "            if choice == \"Load\" and item.endswith(\".png\"):\n",
        "                files.append(filename)\n",
        "            elif choice == \"Create\" and item.endswith(\".pdf\"):\n",
        "                files.append(filename)\n",
        "\n",
        "    filenames, pageNames = imagePages(files, choice)\n",
        "    \n",
        "    targets = [name.split('/')[-1][:5] for name in filenames]\n",
        "    return pageNames, targets, filenames"
      ],
      "metadata": {
        "id": "afQ0EeIreHGT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction funcs"
      ],
      "metadata": {
        "id": "RlLjjCimfuh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#part of preprocessing, this function is going to search for keys(trends) in each byteplot using these trends which are 128 feature array size to create features where the model will be able to decide wether the PDf is benign or malicious (not our contr., i believe the source is the library it self) \n",
        "def describe_keypoints(img, alg, vector_size, descriptor_size, display=False):\n",
        "    # Finding image keypoints\n",
        "    kps = []\n",
        "    try:\n",
        "        kps = alg.detect(img, None)\n",
        "    except:\n",
        "        pass\n",
        "    kps = sorted(kps, key=lambda x: x.response)[:vector_size]\n",
        "    dsc = np.zeros((2, 2))\n",
        "    if len(kps) > 0:\n",
        "        kps, dsc = alg.compute(img, kps)\n",
        "    if len(kps) < vector_size:\n",
        "        dsc = np.zeros(shape=(vector_size, descriptor_size))\n",
        "    dsc = dsc.flatten()\n",
        "    dsc = np.divide(dsc, 256)\n",
        "\n",
        "    return dsc\n",
        "\n",
        "#our contri\n",
        "def extract_SIFT(img):\n",
        "    alg = cv2.xfeatures2d.SIFT_create()\n",
        "    vector_size = 32\n",
        "    descriptor_size = 128\n",
        "    return describe_keypoints(img, alg, vector_size, descriptor_size) #This is were features are extracted from"
      ],
      "metadata": {
        "id": "6Vq918mJfxtX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#features are extracted using pagename(byteplot)\n",
        "def features(pageNames):  \n",
        "    print(\"Should take less than {} minutes.\".format(len(pageNames)*2))\n",
        "    print(\"Please wait...\\n\")\n",
        "    data = []\n",
        "    for pageName in pb.progressbar(pageNames):\n",
        "        gc.collect()\n",
        "        np_load_old = np.load\n",
        "        np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "        images = np.load(pageName)\n",
        "        np.load = np_load_old\n",
        "       \n",
        "        with Pool(processes=3) as pool:\n",
        "            if len(data) == 0:\n",
        "                data = pool.map(extract_SIFT, images, 16)\n",
        "            else:\n",
        "                data = np.concatenate((data, pool.map(extract_SIFT, images, 16)))\n",
        "        os.unlink(pageName)\n",
        "    \n",
        "    return data "
      ],
      "metadata": {
        "id": "29Wtm6sFf3OE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training funcs"
      ],
      "metadata": {
        "id": "TmrNWayOgSk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#our ML models(SVM, RF, DT, KNN) our contribution\n",
        "def train(data, targets, filenames):\n",
        "    targets = [val == \"INFEC\" for val in targets] # Set INFEC as TRUE \n",
        "    options = [\"Support Vector Machine\", \"Random Forest\",\n",
        "            \"Decision Tree Classifier\", \"KNN\"]\n",
        "    res = prompt(\"Choose a ML algorithm:\", options)\n",
        "    \n",
        "    switch = {\n",
        "        0: '/content/drive/MyDrive/Project/Phase3/Implementation/models/SVM.sav',         \n",
        "        # svm.SVC(C=100., random_state=0) \n",
        "        1: '/content/drive/MyDrive/Project/Phase3/Implementation/models/RF.sav',\n",
        "        # RandomForestClassifier(n_estimators=50, max_depth=None, random_state=0)\n",
        "        2: '/content/drive/MyDrive/Project/Phase3/Implementation/models/DT.sav',\n",
        "          #DecisionTreeClassifier(random_state=0),\n",
        "        3: '/content/drive/MyDrive/Project/Phase3/Implementation/models/KNN.sav'\n",
        "         # KNeighborsClassifier(),\n",
        "          \n",
        "    }\n",
        "    \n",
        "\n",
        "    #clf = switch.get(int(res))\n",
        "    filename =  switch.get(int(res))\n",
        "   \n",
        "    # if mode == \"Cross validation\":\n",
        "    #   x=0\n",
        "        #model_evaluation(data, targets, clf)\n",
        "    # elif mode == \"Build and test model\":\n",
        "        # Train model\n",
        "        #clf.fit(data, targets)\n",
        "        \n",
        "        # Save the trained model as a pickle string.\n",
        "        #filename = '/content/drive/MyDrive/Project/Phase3/Implementation/models/SVM.sav'\n",
        "        #filename = '/content/drive/MyDrive/Project/Phase3/Implementation/models/RF.sav'\n",
        "        #filename= '/content/drive/MyDrive/Project/Phase3/Implementation/models/DT.sav'\n",
        "        #filename= '/content/drive/MyDrive/Project/Phase3/Implementation/models/KNN.sav'\n",
        "        \n",
        "        #pickle.dump(clf, open(filename, 'wb'))\n",
        "\n",
        "        # Load the pickled model\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "      \n",
        "    # load the model from disk\n",
        "    \n",
        "    # result = loaded_model.score(X_test, Y_test)\n",
        "    # print(\"loaded model result:\"result)\n",
        "    # Get test dir\n",
        "    while True:\n",
        "        dirname = prompt(\"Which directory are the test files in?\")\n",
        "        if os.path.isdir(dirname):\n",
        "            break\n",
        "        print(\"ERROR: Directory not found.\")\n",
        "\n",
        "    # Set up data/targets for test model\n",
        "    print(\"\\n************************************\")\n",
        "    print(\"*  PREPARING MODEL FOR EVALUATION  *\")\n",
        "    print(\"************************************\")\n",
        "\n",
        "    pageNames, y_true, filenames = process(dirname)    \n",
        "    y_true = [val == \"INFEC\" for val in y_true] # Set INFEC as positive val\n",
        "    test_data = features(pageNames)\n",
        "\n",
        "\n",
        "    # loss, acc = loaded_model.evaluate(test_images, test_labels, verbose=2)\n",
        "    # print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "    # print(new_model.predict(test_images).shape)\n",
        "\n",
        "    y_pred = loaded_model.predict(test_data)\n",
        "\n",
        "    # Use the loaded pickled model to make predictions\n",
        "    # y_pred= loaded_model.predict(test_data)\n",
        "\n",
        "    \n",
        "    print(\"Prediction: \",y_pred)\n",
        "    conf_matrix = skm.confusion_matrix(y_true, y_pred)\n",
        "    accuracy = skm.accuracy_score(y_true, y_pred)\n",
        "    precision = skm.precision_score(y_true, y_pred, average=None)\n",
        "    recall = skm.recall_score(y_true, y_pred, average=None)\n",
        "    f1 = skm.f1_score(y_true, y_pred, average=None)\n",
        "    print(\"Confusion matrix:\\n{}\".format(conf_matrix))\n",
        "    print(\"Accuracy:  {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision[1]))\n",
        "    print(\"Recall:    {}\".format(recall[1]))\n",
        "    print(\"F1:        {}\".format(f1[1]))"
      ],
      "metadata": {
        "id": "x9-IjLBYgV_F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "128Gb0X2gXgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this should show the data fed to model (features), it needs 3 hours of running time so i wasnt able to get outputs before 6 pm\n",
        "doneExtracting = False\n",
        "while not doneExtracting:\n",
        "        pageNames, targets, filenames = process('/content/drive/MyDrive/Project/Phase3/Contagio/Train_sample')#directory \n",
        "        data = features(pageNames)\n",
        "        print(filenames,\"/n\",data,\"/n*****************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC1dX6anOeGu",
        "outputId": "706a2fee-bc5c-44f6-af70-adb8783aab6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4% (3 of 61) |#                        | Elapsed Time: 0:01:43 ETA:   0:33:10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    print(\"\\n************************************\")\n",
        "    print(\"* PDF Image Malware Analysis System *\")\n",
        "    print(\"************************************\")\n",
        "    print('\\nUpload PDF')\n",
        "    # Create images & extract features (until user quits)\n",
        "    doneExtracting = False\n",
        "    while not doneExtracting:\n",
        "        pageNames, targets, filenames = process('/content/drive/MyDrive/Project/Phase3/Contagio/Train')#directory \n",
        "       \n",
        "        data = features(pageNames)\n",
        "\n",
        "        # Create and evaluate model (until user quits)\n",
        "        doneTraining = False\n",
        "        while not doneTraining:\n",
        "            train(data, targets, filenames)\n",
        "            \n",
        "            options = [\"Try another model\", \"Extract new features\", \"Quit\"]\n",
        "            res = options[int(prompt(options=options))]\n",
        "            if res == \"Quit\":\n",
        "                doneTraining = True\n",
        "                doneExtracting = True\n",
        "            elif res == \"Extract new features\":\n",
        "                doneTraining = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "#Train dir\n",
        "#/content/drive/MyDrive/Project/Phase3/Contagio/Train\n",
        "#/content/drive/MyDrive/Project/Phase3/Contagio/Train_sample\n",
        "\n",
        "#/content/drive/MyDrive/Project/Phase3/UserInput\n",
        "\n",
        "#Test dir\n",
        "#/content/drive/MyDrive/Project/Phase3/Contagio/Test\n",
        "#/content/drive/MyDrive/Project/Phase3/Contagio/Test_sample"
      ],
      "metadata": {
        "id": "B1jp9FkCgdC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2e361d-ad5e-49e4-86d3-1fcc2f0dd2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "************************************\n",
            "* PDF Image Malware Analysis System *\n",
            "************************************\n",
            "\n",
            "Upload PDF\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 102) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "  0% (1 of 102) |                        | Elapsed Time: 0:00:18 ETA:   0:30:57"
          ]
        }
      ]
    }
  ]
}